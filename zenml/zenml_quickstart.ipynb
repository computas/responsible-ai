{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *[Title]*\n",
    "\n",
    "**Author:** [Computas AS](https://github.com/computas) ([kontakt@computas.com](mailto:kontakt@computas.com))\n",
    "\n",
    "**Achievement:** *[Short, preferably single-line, statement of what has been accomplished. For example, \"Assuming ... and using ... we show that ...\".]*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "*[Short introduction to this notebook. State motivation, assumptions, method and results in more detail than in the one-line achievement above.]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility and code formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To watermark the environment\n",
    "%load_ext watermark\n",
    "\n",
    "# For automatic code formatting in jupyter lab.\n",
    "%load_ext lab_black\n",
    "\n",
    "# For automatic code formatting in jupyter notebook\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -gb -iv -m -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using Any for unsupported type: typing.Sequence[~T]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# -------\n",
    "\n",
    "# System\n",
    "import sys\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Other packages\n",
    "import zenml\n",
    "from zenml.core.datasources.csv_datasource import CSVDatasource\n",
    "from zenml.core.pipelines.training_pipeline import TrainingPipeline\n",
    "from zenml.core.steps.evaluator.tfma_evaluator import TFMAEvaluator\n",
    "from zenml.core.steps.preprocesser.standard_preprocesser.standard_preprocesser import StandardPreprocesser\n",
    "from zenml.core.steps.split.random_split import RandomSplit\n",
    "from zenml.core.steps.trainer.feedforward_trainer.trainer import FeedForwardTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-22 13:02:10,842 — zenml.core.pipelines.base_pipeline — INFO — Pipeline Quickstart created.\n"
     ]
    }
   ],
   "source": [
    "training_pipeline = TrainingPipeline(name='Quickstart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-22 13:02:33,511 — zenml.core.datasources.base_datasource — INFO — Datasource Pima Indians Diabetes Dataset created.\n"
     ]
    }
   ],
   "source": [
    "# Add a datasource. This will automatically track and version it.\n",
    "ds = CSVDatasource(name='Pima Indians Diabetes Dataset', \n",
    "                   path='gs://zenml_quickstart/diabetes.csv')\n",
    "training_pipeline.add_datasource(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a random 70/30 train-eval split\n",
    "training_pipeline.add_split(RandomSplit(split_map={'train': 0.7, 'eval': 0.3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardPreprocesser() has sane defaults for normal preprocessing methods\n",
    "training_pipeline.add_preprocesser(\n",
    "    StandardPreprocesser(\n",
    "        features=['times_pregnant', 'pgc', 'dbp', 'tst', 'insulin', 'bmi',\n",
    "                  'pedigree', 'age'],\n",
    "        labels=['has_diabetes'],\n",
    "        overwrite={'has_diabetes': {\n",
    "            'transform': [{'method': 'no_transform', 'parameters': {}}]}}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a trainer\n",
    "training_pipeline.add_trainer(FeedForwardTrainer(\n",
    "    loss='binary_crossentropy',\n",
    "    last_activation='sigmoid',\n",
    "    output_units=1,\n",
    "    metrics=['accuracy'],\n",
    "    epochs=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an evaluator\n",
    "training_pipeline.add_evaluator(\n",
    "    TFMAEvaluator(slices=[['has_diabetes']],\n",
    "                  metrics={'has_diabetes': ['binary_crossentropy',\n",
    "                                            'binary_accuracy']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-22 13:03:14,790 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataGen is running.\n",
      "Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "form_ExtractEvaluateAndWriteResults/BatchedInputsToExtracts/AddArrowRecordBatchKey_24))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractBatchedInputs/ExtractInputs_27))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractBatchPredictions/Predict_29))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractUnbatchedInputs/UnbatchInputs_31))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractSliceKeys/ParDo(ExtractSliceKeysFn)_33))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/Preprocesss_36))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/DoSlicing_38))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/ExtractSliceKeys_40))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ExtractSliceKeys_63))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/ParDo(SplitHotCold)/ParDo(SplitHotCold)_84))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/ToPairs_42))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/Group/Precombine))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/Group/Group/Write))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/CountPerSliceKey/CountPerSliceKey:PairWithVoid_65))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/CountPerSliceKey/CombinePerKey(CountCombineFn)/Precombine))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/CountPerSliceKey/CombinePerKey(CountCombineFn)/Group/Write))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/Flatten/Transcode/0))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/WindowIntoDiscarding_85))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PreCombineFn)/Precombine))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PreCombineFn)/Group/Write))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/Flatten/Write/0)\n",
      "Running (((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PreCombineFn)/Group/Read)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PreCombineFn)/Merge))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PreCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/Map(StripNonce)_90))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/WindowIntoOriginal_91))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/Flatten/Write/1)\n",
      "Running ((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/Flatten/Read)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PostCombineFn)/Precombine))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PostCombineFn)/Group/Write)\n",
      "Running (((((((((((((((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PostCombineFn)/Group/Read)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PostCombineFn)/Merge))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/CombinePerKey(PostCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/ConvertAndAddDerivedValues_97))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/AddDiffMetrics_99))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FilterByMetrics_100))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FilterByPlots_101))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ValidateMetrics_102))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/ConvertSliceMetricsToProto_126))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/ConvertSlicePlotsToProto_142))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/KeyWithVoid_159))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/Map(<lambda at iobase.py:1078>)_136))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/WindowInto(WindowIntoFn)_137))+(ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/GroupByKey/Write))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/Map(<lambda at iobase.py:1078>)_152))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/WindowInto(WindowIntoFn)_153))+(ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/GroupByKey/Write))+((ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/CombinePerKey/Precombine)+(ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/CombinePerKey/Group/Write))\n",
      "Running ((((ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/CombinePerKey/Group/Read)+(ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/CombinePerKey/Merge))+(ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/UnKey_164))+(ref_PCollection_PCollection_94/Write)\n",
      "Running ((((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/DoOnce/Impulse_166)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/DoOnce/FlatMap(<lambda at core.py:3024>)_167))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/DoOnce/Map(decode)_169))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/MergeValidationResults/InjectDefault_170))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/Map(<lambda at iobase.py:1078>)_180))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/WindowInto(WindowIntoFn)_181))+(ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/GroupByKey/Write)\n",
      "Running ((ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/WriteBundles_183))+(ref_PCollection_PCollection_106/Write)\n",
      "Running ((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/CountPerSliceKey/CombinePerKey(CountCombineFn)/Group/Read)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/CountPerSliceKey/CombinePerKey(CountCombineFn)/Merge))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/CountPerSliceKey/CombinePerKey(CountCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/IncrementSliceSpecCounters/GetSliceCountKeys_78))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/IncrementSliceSpecCounters/Count_79)\n",
      "Running (((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/CreateEvalConfig/Impulse_106)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/CreateEvalConfig/FlatMap(<lambda at core.py:3024>)_107))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/CreateEvalConfig/Map(decode)_109))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/Map(<lambda at iobase.py:1078>)_119))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/WindowInto(WindowIntoFn)_120))+(ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/GroupByKey/Write)\n",
      "Running (((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/DoOnce/Impulse_114)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/DoOnce/FlatMap(<lambda at core.py:3024>)_115))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/DoOnce/Map(decode)_117))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/InitializeWrite_118))+(ref_PCollection_PCollection_61/Write))+(ref_PCollection_PCollection_62/Write)\n",
      "Running ((ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/WriteBundles_122))+(ref_PCollection_PCollection_66/Write)\n",
      "Running ((ref_PCollection_PCollection_61/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/PreFinalize_123))+(ref_PCollection_PCollection_67/Write)\n",
      "Running (ref_PCollection_PCollection_61/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteEvalConfig/WriteEvalConfig/Write/WriteImpl/FinalizeWrite_124)\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.01 seconds.\n",
      "Running ((ref_PCollection_PCollection_101/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/PreFinalize_184))+(ref_PCollection_PCollection_107/Write)\n",
      "Running (((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/Group/Group/Read)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/Group/Merge))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/Group/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/Distinct_47))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/KeyWithVoid_50))+((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))\n",
      "Running ((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Merge))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/UnKey_55))+(ref_PCollection_PCollection_25/Write)\n",
      "Running ((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/DoOnce/Impulse_57)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/DoOnce/FlatMap(<lambda at core.py:3024>)_58))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/DoOnce/Map(decode)_60))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/InjectDefault_61))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/FanoutSlices/TrackDistinctSliceKeys/IncrementCounter_62)\n",
      "Running (ref_PCollection_PCollection_101/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteValidationsToTFRecord/Write/WriteImpl/FinalizeWrite_185)\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.01 seconds.\n",
      "Running (((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/DoOnce/Impulse_147)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/DoOnce/FlatMap(<lambda at core.py:3024>)_148))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/DoOnce/Map(decode)_150))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/InitializeWrite_151))+(ref_PCollection_PCollection_83/Write))+(ref_PCollection_PCollection_84/Write)\n",
      "Running ((ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/WriteBundles_155))+(ref_PCollection_PCollection_88/Write)\n",
      "Running ((ref_PCollection_PCollection_83/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/PreFinalize_156))+(ref_PCollection_PCollection_89/Write)\n",
      "Running (ref_PCollection_PCollection_83/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WritePlotsToTFRecord/Write/WriteImpl/FinalizeWrite_157)\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.01 seconds.\n",
      "Running (((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/DoOnce/Impulse_131)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/DoOnce/FlatMap(<lambda at core.py:3024>)_132))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/DoOnce/Map(decode)_134))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/InitializeWrite_135))+(ref_PCollection_PCollection_72/Write))+(ref_PCollection_PCollection_73/Write)\n",
      "Running ((ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/WriteBundles_139))+(ref_PCollection_PCollection_77/Write)\n",
      "Running ((ref_PCollection_PCollection_72/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/PreFinalize_140))+(ref_PCollection_PCollection_78/Write)\n",
      "Running (ref_PCollection_PCollection_72/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteMetricsAndPlots/WriteMetrics/Write/WriteImpl/FinalizeWrite_141)\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.01 seconds.\n",
      "2021-01-22 13:03:58,743 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Evaluator is finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline locally\n",
    "training_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   Type  Presence Valency Domain\nFeature name                                    \n'age'             FLOAT  required  single      -\n'bmi'             FLOAT  required  single      -\n'dbp'             FLOAT  required  single      -\n'has_diabetes'    FLOAT  required  single      -\n'insulin'         FLOAT  required  single      -\n'pedigree'        FLOAT  required  single      -\n'pgc'             FLOAT  required  single      -\n'times_pregnant'  FLOAT  required  single      -\n'tst'             FLOAT  required  single      -",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Presence</th>\n      <th>Valency</th>\n      <th>Domain</th>\n    </tr>\n    <tr>\n      <th>Feature name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>'age'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'bmi'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'dbp'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'has_diabetes'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'insulin'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'pedigree'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'pgc'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'times_pregnant'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>'tst'</th>\n      <td>FLOAT</td>\n      <td>required</td>\n      <td>single</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# See schema of data\n",
    "training_pipeline.view_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-22 13:04:31,169 — zenml.core.pipelines.training_pipeline — INFO — Viewing statistics. If magic=False then a new window will open up with a notebook for evaluation. If magic=True, then an attempt will be made to append to the current notebook.\n",
      "Starting Bokeh server version 1.4.0 (running on Tornado 6.1)\n",
      "User authentication hooks NOT provided (default user enabled)\n",
      "Launching server at http://localhost:39455\n",
      "200 GET / (127.0.0.1) 14.11ms\n",
      "200 GET /static/js/bokeh.min.js?v=3e3c0eee857419c9d818b81fee3c130027f3a211949247db518cc67221e9bb741a2c32baa08d53d817cced9cf5b7e8185331a4e05acdf87a4b5498f8476f941e (127.0.0.1) 1.76ms\n",
      "200 GET /static/js/bokeh-widgets.min.js?v=20fca0f0ecad0fdbcf7efe518caf4ace2c0657c2e405f6c74e06cdd1ffe03c2a512b1aa34d43f2fbe18cd7c0a9a359d98d39446a4940c928c1606bcc9433d54e (127.0.0.1) 2.02ms\n",
      "200 GET /static/js/bokeh-tables.min.js?v=86ab633bbdeea2ee5157a1cf15d677b3c6061cfb00a663cb70619dfcfc86c116781eaf630541df4bcfb7083d08cc7475af79dbb5b3f83a20faa6716bee97f3f7 (127.0.0.1) 3.88ms\n",
      "200 GET /static/js/bokeh-gl.min.js?v=d1a6bb57f40b68e67109fe97d9160333a4dfe4dceefd7bcbdb312cef5bb12e8079ad8c77385a6af51c2fc9cb3bb6474627544c9764a61cc5677b090c0df90814 (127.0.0.1) 7.77ms\n",
      "404 GET /favicon.ico (127.0.0.1) 0.40ms\n",
      "101 GET /ws?bokeh-protocol-version=1.0&bokeh-session-id=0qCVwXTmbMKJBqcIfWgzxajfYxMitWJ74v7HAR9R7JHN (127.0.0.1) 0.64ms\n",
      "WebSocket connection opened\n",
      "ServerConnection created\n"
     ]
    }
   ],
   "source": [
    "# See statistics of train and eval\n",
    "training_pipeline.view_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-22 13:41:27,134 — zenml.core.pipelines.training_pipeline — INFO — Evaluating pipeline. If magic=False then a new window will open up with a notebook for evaluation. If magic=True, then an attempt will be made to append to the current notebook.\n"
     ]
    }
   ],
   "source": [
    "# Creates a notebook for evaluation\n",
    "training_pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('zenml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "124d21db1b4c3052120663363a6852957385b8ea573b9ce075fb9110c02d54d5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}